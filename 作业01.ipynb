{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(z):\n",
    "    return 1/(1+math.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import configparser\n",
    "import numpy as np\n",
    "def load_data(data_file,usecols):\n",
    "    data=[]\n",
    "    with open(\"D:\\mytyle\\人工神经网络\\BeijingPM20100101_20151231.csv\",'r') as csvfile:\n",
    "        data_reader=csv.DictReader(csvfile)\n",
    "        for row in data_reader:\n",
    "            row_data=[]\n",
    "            for col in usecols:\n",
    "                str_val=row[col]\n",
    "                row_data.append(float(str_val) if str_val!='NA' else np.nan)\n",
    "                if not any(np.isnan(row_data)):\n",
    "                    data.append(row_data)\n",
    "                    data_arr=np.array(data)\n",
    "                    return data_arr\n",
    "def get_polluted_perc(data_arr):\n",
    "    hour_val=np.mean(data_arr[:,6:8],axis=1)\n",
    "    n_hours=hour_val.shape[0]\n",
    "    n_heavy_hours=hour_val[hour_val>150].shape[0]\n",
    "    n_medium_hours=hour_val[(hour_val>75) & (hour_val<=150)].shape[0]\n",
    "    n_light_hours = hour_val[(hour_val > 35) & (hour_val <= 75)].shape[0]\n",
    "    n_good_hours = hour_val[hour_val <= 35].shape[0]\n",
    "    polluted_perc_list= [n_heavy_hours / n_hours, n_medium_hours / n_hours,\n",
    "                          n_light_hours / n_hours, n_good_hours / n_hours]\n",
    "    return polluted_perc_list\n",
    "def save_stats_to_csv(results_arr,save_file,headers):\n",
    "    with open(save_file,'w',newline='') as csvfile:\n",
    "        writer=csv.writer(csvfile)\n",
    "        writer.writerow(headers)\n",
    "        for row in results_arr.tolist():\n",
    "            writer.writerow(row)\n",
    "def main():\n",
    "    polluted_state_list=[]\n",
    "    for city_name,(filename,cols) in config.data_config_dict.items():\n",
    "        data_file=os.path.join(config.dataset_path,filename)\n",
    "        usecols=config.common_cols+['PM_'+col for col in cols]\n",
    "        data_arr=load_data(data_file,usecols)\n",
    "        print('{}共有{}行有效数据'.format(city_name,data_arr.shape[0]))\n",
    "        print('{}的前10行数据：'.format(city_name))\n",
    "        print(data_arr[:10])\n",
    "        polluted_perc_list=get_polluted_perc(data_arr)\n",
    "        polluted_state_list.append([city_name]+polluted_perc_list)\n",
    "        print('{}的污染小时数百分比{}'.format(city_name,polluted_perc_list))\n",
    "        results_arr=get_avg_pm_per_month(data_arr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
